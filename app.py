 
# app.py
import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats
import sympy as sp
from sklearn.linear_model import LinearRegression, LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC
from sklearn.model_selection import train_test_split, cross_val_score, KFold
from sklearn.metrics import (accuracy_score, classification_report,
                           confusion_matrix, mean_squared_error, r2_score,
                           roc_auc_score, roc_curve, precision_recall_curve, auc)
from sklearn.datasets import make_classification, load_iris
from sklearn.preprocessing import PolynomialFeatures
from sklearn.pipeline import Pipeline
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots

# Configuration de la page
st.set_page_config(
    page_title="üìö Cours Interactif de Data Science",
    page_icon="üß†",
    layout="wide",
    initial_sidebar_state="expanded"
)

# CSS personnalis√©
st.markdown("""
<style>
    .main-header {
        font-size: 3rem;
        color: #1f77b4;
        text-align: center;
        margin-bottom: 2rem;
    }
    .module-card {
        padding: 1.5rem;
        border-radius: 10px;
        border-left: 5px solid #1f77b4;
        background-color: #f0f2f6;
        margin-bottom: 1rem;
    }
    .exercise-box {
        background-color: #e8f4fd;
        padding: 1rem;
        border-radius: 10px;
        border: 2px solid #1f77b4;
        margin: 1rem 0;
    }
    .success-box {
        background-color: #d4edda;
        padding: 1rem;
        border-radius: 10px;
        border: 2px solid #28a745;
    }
    .concept-card {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
        padding: 1.5rem;
        border-radius: 10px;
        margin: 1rem 0;
    }
    .glossary-box {
        background-color: #f8f9fa;
        padding: 1rem;
        border-radius: 5px;
        border-left: 3px solid #6c757d;
    }
</style>
""", unsafe_allow_html=True)

# Sidebar navigation
st.sidebar.title("üéì Navigation du Cours")
st.sidebar.markdown("---")

# Glossaire dans la sidebar
with st.sidebar.expander("üìï Glossaire"):
    st.markdown("""
    - **DataFrame** : Structure de donn√©es tabulaire (comme un tableau Excel).
    - **p-value** : Probabilit√© que les r√©sultats soient dus au hasard. **< 0.05** = significatif.
    - **AUC-ROC** : Aire sous la courbe ROC (1 = mod√®le parfait, 0.5 = hasard).
    - **Overfitting** : Mod√®le trop complexe qui m√©morise les donn√©es d'entra√Ænement.
    - **Corr√©lation** : Relation entre deux variables (-1 √† 1).
    - **Biais-Variance** : √âquilibre entre sous-apprentissage et surapprentissage.
    - **Feature** : Variable explicative (ex. : √¢ge, revenu).
    - **Target** : Variable √† pr√©dire (ex. : remboursement d'un pr√™t).
    """)

# S√©lection du module
module = st.sidebar.radio(
    "Choisissez un module:",
    ["üè† Accueil", "üìä Module 1 - Fondations (Pandas)", "üìà Module 2 - Statistiques",
     "üßÆ Module 3 - Math√©matiques", "ü§ñ Module 4 - ML Introduction",
     "üå≤ Module 5 - Algorithmes ML", "üè¶ Module 6 - Projet Scoring Cr√©dit",
     "üéì Module 7 - Quiz Interactif", "üè¶ Module 8 - Projet Immobilier", "üìò √Ä Propos"]
)

# Page d'accueil
if module == "üè† Accueil":
    st.markdown('<h1 class="main-header">üìö Cours Interactif de Data Science</h1>', unsafe_allow_html=True)

    col1, col2 = st.columns([2, 1])

    with col1:
        st.markdown("""
        ## üåü Bienvenue dans ce cours interactif !

        **Pourquoi ce cours ?**
        La Data Science est partout :
        - **Netflix** utilise des algorithmes pour recommander des films.
        - **Les banques** pr√©disent les risques de cr√©dit.
        - **Les h√¥pitaux** optimisent les traitements avec l'IA.

        ### üéØ Ce que vous allez apprendre :
        1. **Manipuler des donn√©es** avec Pandas et NumPy.
        2. **Analyser des statistiques** et tester des hypoth√®ses.
        3. **Comprendre les maths** derri√®re le Machine Learning.
        4. **Construire des mod√®les** pr√©dictifs.
        5. **R√©soudre un cas r√©el** : un syst√®me de scoring cr√©dit.

        ### üõ† Comment utiliser cette application ?
        - **Exp√©rimentez** avec les param√®tres interactifs.
        - **Lisez les explications** et exemples concrets.
        - **R√©solvez les exercices** pour valider vos connaissances.
        - **Visualisez les r√©sultats** en temps r√©el.

        **Public cible** : D√©butants en Data Science, analystes, ou toute personne curieuse !
        """)

    with col2:
        st.image("https://cdn-icons-png.flaticon.com/512/2103/2103633.png", width=200)
        st.info("üí° **Conseil** : Ex√©cutez les codes et jouez avec les param√®tres pour mieux comprendre !")

    # M√©triques du cours
    st.markdown("---")
    col1, col2, col3, col4 = st.columns(4)
    with col1:
        st.metric("‚è± Dur√©e estim√©e", "6 heures", "Auto-rythm√©")
    with col2:
        st.metric("üìä Modules", "6", "De la th√©orie √† la pratique")
    with col3:
        st.metric("üí° Concepts cl√©s", "50+", "Explicit√©s simplement")
    with col4:
        st.metric("üöÄ Projet final", "1", "Scoring cr√©dit r√©aliste")

    # T√©moignage fictif
    st.markdown("---")
    st.markdown("""
    > *"Ce cours m'a permis de passer de z√©ro √† un projet concret en quelques heures !
    > Les explications sont claires et les exemples tr√®s pratiques."*
    > **‚Äî Marie, Analyste Marketing**
    """)

# Module 1 - Fondations (Pandas)
elif module == "üìä Module 1 - Fondations (Pandas)":
    st.header("üìä Module 1 - Fondations de la Data Science avec Pandas")

    st.markdown("""
    ### üéØ **Objectifs de ce Module**
    - Comprendre les **DataFrames** et leur manipulation.
    - Calculer des **statistiques descriptives**.
    - Nettoyer et explorer des donn√©es r√©elles.
    """)

    tab1, tab2, tab3, tab4 = st.tabs(["üìö Introduction", "üêç Pandas en Pratique", "üìã Exercice", "‚úÖ Solution"])

    with tab1:
        st.markdown("""
        #### üí° **Concept Cl√© : Qu'est-ce qu'un DataFrame ?**
        Un **DataFrame** est une structure de donn√©es **tabulaire** (comme un tableau Excel), avec :
        - **Des lignes** = Observations (ex. : clients, produits).
        - **Des colonnes** = Variables (ex. : √¢ge, prix, cat√©gorie).
        - **Un index** = Identifiant unique pour chaque ligne.

        **Exemple** :
        | Client   | √Çge | Revenu | Achat |
        |----------|-----|--------|-------|
        | Client_1 | 25  | 3000‚Ç¨  | Oui   |
        | Client_2 | 40  | 5000‚Ç¨  | Non   |

        **Analogie** :
        > *"Un DataFrame est comme une **feuille Excel intelligente** :
        > - Vous pouvez **filtrer** (ex. : clients de plus de 30 ans).
        > - **Grouper** (ex. : revenu moyen par √¢ge).
        > - **Visualiser** en 2 clics !"*

        ---

        #### üìñ **Pourquoi Pandas ?**
        - **80% du travail en Data Science** = Nettoyage et exploration de donn√©es.
        - Pandas permet de :
          1. **Lire** des fichiers (CSV, Excel, SQL).
          2. **Nettoyer** (valeurs manquantes, doublons).
          3. **Transformer** (cr√©er de nouvelles colonnes).
          4. **Analyser** (moyennes, corr√©lations).

        **Cas d'usage r√©el** :
        > *"Un supermarch√© utilise Pandas pour :
        > - Identifier les **produits les plus vendus** par tranche d'√¢ge.
        > - D√©tecter les **p√©riodes de forte affluence**.
        > - Optimiser les **stocks** en fonction des tendances."*
        """)

    with tab2:
        st.subheader("üêç Manipulation de donn√©es avec Pandas")

        st.markdown("""
        #### üìå **G√©n√©rateur de donn√©es interactif**
        Cr√©ez un jeu de donn√©es personnalis√© pour exp√©rimenter !
        """)

        col1, col2 = st.columns(2)
        with col1:
            n_clients = st.slider("Nombre de clients", 5, 50, 10)
            min_montant = st.number_input("Montant minimum (‚Ç¨)", 50, 500, 100)
            max_montant = st.number_input("Montant maximum (‚Ç¨)", 500, 2000, 1000)
        with col2:
            categories = st.multiselect(
                "Cat√©gories de d√©pense",
                ["Alimentation", "Loisirs", "Transport", "Logement"],
                default=["Alimentation", "Loisirs", "Transport"]
            )

        if st.button("üîÑ G√©n√©rer les donn√©es"):
            np.random.seed(42)
            data = {
                "Client": [f"Client_{i+1}" for i in range(n_clients)],
                "Montant": np.random.randint(min_montant, max_montant, n_clients),
                "Cat√©gorie": np.random.choice(categories, n_clients)
            }
            df = pd.DataFrame(data)
            st.session_state.df_module1 = df
            st.balloons()

        if 'df_module1' in st.session_state:
            df = st.session_state.df_module1

            col1, col2 = st.columns(2)
            with col1:
                st.subheader("üìÑ DataFrame")
                st.dataframe(df, use_container_width=True)
            with col2:
                st.subheader("üìä Statistiques descriptives")
                stats = df["Montant"].describe()
                st.dataframe(stats, use_container_width=True)
                st.markdown(f"""
                **Interpr√©tation** :
                - **Moyenne** : {stats['mean']:.2f}‚Ç¨ (d√©pense typique).
                - **√âcart-type** : {stats['std']:.2f}‚Ç¨ (variabilit√©).
                - **50% des clients** d√©pensent **moins de** {stats['50%']:.2f}‚Ç¨.
                """)

            # Visualisations
            st.subheader("üìà Visualisations")
            fig_col1, fig_col2 = st.columns(2)
            with fig_col1:
                fig = px.histogram(df, x="Montant", title="Distribution des montants",
                                  nbins=10, color_discrete_sequence=['#1f77b4'])
                st.plotly_chart(fig, use_container_width=True, key="histogram_montants_module1")
            with fig_col2:
                category_stats = df.groupby("Cat√©gorie")["Montant"].mean().reset_index()
                fig = px.bar(category_stats, x="Cat√©gorie", y="Montant",
                           title="D√©pense moyenne par cat√©gorie",
                           color="Cat√©gorie", color_discrete_sequence=px.colors.qualitative.Set3)
                st.plotly_chart(fig, use_container_width=True, key="bar_categories_module1")

            st.markdown("""
            **üí° Insight** :
            - La cat√©gorie **"Logement"** est souvent la plus co√ªteuse.
            - La **distribution** montre si les d√©penses sont concentr√©es ou √©tal√©es.
            """)

    with tab3:
        st.markdown('<div class="exercise-box">', unsafe_allow_html=True)
        st.subheader("üìã Exercice Pratique : Analyse de Salaires")

        st.markdown("""
        **Sc√©nario** :
        Vous √™tes RH dans une entreprise et vous avez les donn√©es suivantes pour 15 employ√©s :
        - **√Çge** (20-60 ans)
        - **Salaire** (2000-8000‚Ç¨)

        **Questions** :
        1. Quelle est la **moyenne** et l'**√©cart-type** des salaires ?
        2. Y a-t-il une **corr√©lation** entre √¢ge et salaire ?
        3. Quel est le **salaire m√©dian** pour les 20-30 ans vs 50-60 ans ?

        **Indice** : Utilisez `df.groupby()` et `df.corr()`.
        """)

        if st.button("üßπ G√©n√©rer les donn√©es d'exercice"):
            np.random.seed(123)
            ages = np.random.randint(20, 61, 15)
            salaires = np.random.randint(2000, 8001, 15)
            st.session_state.df_exercise = pd.DataFrame({
                "Age": ages,
                "Salaire": salaires
            })

        if 'df_exercise' in st.session_state:
            st.dataframe(st.session_state.df_exercise, use_container_width=True)

            user_code = st.text_area("üíª Votre code Python :", height=150,
                                    placeholder="""import pandas as pd
# 1. Calculer moyenne et √©cart-type des salaires
moyenne = df["Salaire"].mean()
ecart_type = df["Salaire"].std()

# 2. Corr√©lation √¢ge-salaire
correlation = df["Age"].corr(df["Salaire"])

# 3. Salaire m√©dian par tranche d'√¢ge
df["Tranche_Age"] = pd.cut(df["Age"], bins=[20, 30, 40, 50, 60], labels=["20-30", "31-40", "41-50", "51-60"])
median_par_tranche = df.groupby("Tranche_Age")["Salaire"].median()""")

            if st.button("üì§ Soumettre la solution"):
                st.success("‚úÖ Code soumis ! V√©rifiez l'onglet **Solution**.")

        st.markdown('</div>', unsafe_allow_html=True)

    with tab4:
        st.subheader("‚úÖ Solution et Interpr√©tation")

        if 'df_exercise' in st.session_state:
            df = st.session_state.df_exercise.copy()

            # Solution code
            code_solution = """
# 1. Statistiques salariales
moyenne = df["Salaire"].mean()
ecart_type = df["Salaire"].std()

# 2. Corr√©lation √¢ge-salaire
correlation = df["Age"].corr(df["Salaire"])

# 3. Tranches d'√¢ge et salaire m√©dian
bins = [20, 30, 40, 50, 60]
labels = ["20-30", "31-40", "41-50", "51-60"]
df["Tranche_Age"] = pd.cut(df["Age"], bins=bins, labels=labels)
median_par_tranche = df.groupby("Tranche_Age")["Salaire"].median()
"""
            st.code(code_solution, language='python')

            # Ex√©cution
            moyenne = df["Salaire"].mean()
            ecart_type = df["Salaire"].std()
            correlation = df["Age"].corr(df["Salaire"])
            bins = [20, 30, 40, 50, 60]
            labels = ["20-30", "31-40", "41-50", "51-60"]
            df["Tranche_Age"] = pd.cut(df["Age"], bins=bins, labels=labels)
            median_par_tranche = df.groupby("Tranche_Age")["Salaire"].median()

            col1, col2 = st.columns(2)
            with col1:
                st.metric("Moyenne des salaires", f"{moyenne:.2f} ‚Ç¨")
                st.metric("√âcart-type", f"{ecart_type:.2f} ‚Ç¨")
                st.metric("Corr√©lation √¢ge-salaire", f"{correlation:.3f}")
            with col2:
                st.markdown("**Salaire m√©dian par tranche d'√¢ge**")
                st.dataframe(median_par_tranche.to_frame().style.background_gradient(cmap='Blues'))

            # Visualisation
            fig = px.scatter(df, x="Age", y="Salaire", color="Tranche_Age",
                           title="Relation √Çge-Salaire",
                           color_discrete_sequence=px.colors.qualitative.Set1)
            fig.update_layout(xaxis_title="√Çge", yaxis_title="Salaire (‚Ç¨)")
            st.plotly_chart(fig, use_container_width=True, key="scatter_age_salaire_solution")

            st.markdown(f"""
            **üîç Analyse** :
            - **Corr√©lation positive** ({correlation:.3f}) : Les employ√©s plus √¢g√©s gagnent g√©n√©ralement plus.
            - **√âcart de salaire** : Les 51-60 ans gagnent **{median_par_tranche['51-60'] - median_par_tranche['20-30']:.2f}‚Ç¨** de plus que les 20-30 ans.
            """)

# Module 2 - Statistiques
elif module == "üìà Module 2 - Statistiques":
    st.header("üìà Module 2 - Statistiques pour la Data Science")

    st.markdown("""
    ### üéØ **Objectifs de ce Module**
    - Comprendre les **distributions** (normale, uniforme, etc.).
    - Ma√Ætriser les **tests d'hypoth√®ses** (test t, p-value).
    - Interpr√©ter des **intervalles de confiance**.
    """)

    tab1, tab2, tab3, tab4 = st.tabs(["üé≤ Distributions", "üî¨ Tests d'Hypoth√®ses", "üìã Exercice", "‚úÖ Solution"])

    with tab1:
        st.subheader("üé≤ Distributions et Statistiques Descriptives")

        st.markdown("""
        #### üí° **Concept Cl√© : Types de Distributions**
        | Distribution  | Forme               | Exemple R√©aliste                          |
        |---------------|---------------------|-------------------------------------------|
        | **Normale**   | üîî (Courbe en cloche) | Taille des humains, notes d'examen.       |
        | **Uniforme**  | ‚ñá‚ñá‚ñá‚ñá‚ñá (Plate)        | R√©sultat d'un d√© √©quilibr√©.               |
        | **Poisson**   | üìä (Asym√©trique)     | Nombre d'emails spam par jour.            |
        | **Binomiale** | üé≤ (Succ√®s/Echec)    | Taux de clics sur une publicit√©.          |

        **Analogie** :
        > *"- **Normale** : La plupart des gens ont une taille autour de 170 cm (moyenne), peu sont tr√®s grands ou tr√®s petits.
        > - **Poisson** : Peu de jours avec 10 spams, beaucoup avec 0 ou 1.
        > - **Binomiale** : 10% de chance de gagner √† la loterie √† chaque essai."
        """)

        # S√©lecteur de distribution
        distribution = st.selectbox("Choisissez une distribution :", ["Normale", "Uniforme", "Poisson", "Binomiale"])

        col1, col2 = st.columns(2)
        with col1:
            n_points = st.slider("Nombre de points", 100, 10000, 1000)
            if distribution == "Normale":
                mean = st.slider("Moyenne", -5.0, 5.0, 0.0)
                std = st.slider("√âcart-type", 0.1, 5.0, 1.0)
                data = np.random.normal(mean, std, n_points)
            elif distribution == "Uniforme":
                low = st.slider("Borne inf√©rieure", -10, 0, -5)
                high = st.slider("Borne sup√©rieure", 0, 10, 5)
                data = np.random.uniform(low, high, n_points)
            elif distribution == "Poisson":
                lam = st.slider("Lambda (Œª)", 1, 20, 5)
                data = np.random.poisson(lam, n_points)
            else:  # Binomiale
                n_trials = st.slider("Nombre d'essais (n)", 1, 100, 10)
                p = st.slider("Probabilit√© de succ√®s (p)", 0.0, 1.0, 0.5)
                data = np.random.binomial(n_trials, p, n_points)

        with col2:
            # Calcul des statistiques
            stats_df = pd.DataFrame({
                'M√©trique': ['Moyenne', 'M√©diane', '√âcart-type', 'Skewness (asym√©trie)', 'Kurtosis (aplatissement)'],
                'Valeur': [
                    np.mean(data),
                    np.median(data),
                    np.std(data),
                    stats.skew(data),
                    stats.kurtosis(data)
                ]
            })
            st.dataframe(stats_df.style.background_gradient(cmap='Blues'), use_container_width=True)

        # Visualisation
        fig = make_subplots(rows=1, cols=2, subplot_titles=('Histogramme', 'Bo√Æte √† moustaches'))
        fig.add_trace(go.Histogram(x=data, nbinsx=50, name='Distribution', marker_color='#1f77b4'), row=1, col=1)
        fig.add_trace(go.Box(y=data, name='Bo√Æte √† moustaches', marker_color='#1f77b4'), row=1, col=2)
        fig.update_layout(height=400, showlegend=False)
        st.plotly_chart(fig, use_container_width=True, key="distribution_visualization")

        st.markdown("""
        **üí° Interpr√©tation** :
        - **Skewness > 0** : Queue √† droite (ex. : revenus, quelques personnes tr√®s riches).
        - **Kurtosis > 0** : Pic plus pointu que la normale (donn√©es concentr√©es).
        """)

    with tab2:
        st.subheader("üî¨ Tests d'Hypoth√®ses - Test t de Student")

        st.markdown("""
        #### üìñ **Pourquoi faire un test t ?**
        - **Comparer deux groupes** (ex. : m√©thode A vs m√©thode B).
        - **R√©pondre √† une question** : "La nouvelle version du site convertit-elle mieux ?"
        - **√âviter les conclusions h√¢tives** : Une diff√©rence de 1% peut √™tre due au hasard !

        **Exemple** :
        > *"Un site e-commerce teste deux couleurs de bouton :
        > - **Groupe A** (Bouton rouge) : Taux de conversion = 2%.
        > - **Groupe B** (Bouton vert) : Taux de conversion = 2.5%.
        > Le test t dit si cette diff√©rence est **statistiquement significative**."
        """)

        col1, col2 = st.columns(2)
        with col1:
            st.markdown("**Groupe A (Contr√¥le)")
            mean_a = st.slider("Moyenne Groupe A", 50, 100, 75, key="mean_a")
            std_a = st.slider("√âcart-type Groupe A", 1, 20, 10, key="std_a")
            n_a = st.slider("Taille Groupe A", 10, 100, 30, key="n_a")
        with col2:
            st.markdown("**Groupe B (Nouveau)")
            mean_b = st.slider("Moyenne Groupe B", 50, 100, 78, key="mean_b")
            std_b = st.slider("√âcart-type Groupe B", 1, 20, 12, key="std_b")
            n_b = st.slider("Taille Groupe B", 10, 100, 30, key="n_b")

        if st.button("üß™ Ex√©cuter le test t"):
            np.random.seed(42)
            groupe_A = np.random.normal(mean_a, std_a, n_a)
            groupe_B = np.random.normal(mean_b, std_b, n_b)
            t_stat, p_value = stats.ttest_ind(groupe_A, groupe_B)

            st.markdown("### üìä R√©sultats")
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("Statistique t", f"{t_stat:.3f}")
            with col2:
                st.metric("p-value", f"{p_value:.4f}")
            with col3:
                significance = "‚úÖ Significatif" if p_value < 0.05 else "‚ùå Non significatif"
                st.metric("Conclusion", significance)

            # Visualisation comparative
            fig = go.Figure()
            fig.add_trace(go.Box(y=groupe_A, name='Groupe A', boxpoints='all', marker_color='#1f77b4'))
            fig.add_trace(go.Box(y=groupe_B, name='Groupe B', boxpoints='all', marker_color='#ff7f0e'))
            fig.update_layout(title='Comparaison des groupes - Boxplots', yaxis_title='Valeurs')
            st.plotly_chart(fig, use_container_width=True, key="boxplot_ttest")

            st.markdown("""
            **üîç Conclusion** :
            - Si **p < 0.05**, la diff√©rence est **r√©elle** (pas due au hasard).
            - Sinon, il faut **plus de donn√©es** ou accepter qu'il n'y a pas de diff√©rence.
            """)

    with tab3:
        st.markdown('<div class="exercise-box">', unsafe_allow_html=True)
        st.subheader("üìã Exercice Pratique - Analyse Statistique")

        st.markdown("""
        **Sc√©nario** :
        Une entreprise teste deux m√©thodes de formation pour ses employ√©s.
        - **Groupe A** : M√©thode traditionnelle (30 employ√©s).
        - **Groupe B** : Nouvelle m√©thode interactive (30 employ√©s).
        Les scores de performance (sur 100) sont collect√©s.

        **Questions** :
        1. Les donn√©es suivent-elles une distribution normale ?
        2. La nouvelle m√©thode est-elle **significativement meilleure** ?
        3. Quelle est la **taille d'effet** (Cohen's d) ?
        """)

        if st.button("üé≤ G√©n√©rer les donn√©es d'exercice"):
            np.random.seed(123)
            groupe_A = np.random.normal(72, 8, 30)
            groupe_A = np.clip(groupe_A, 50, 95)
            groupe_B = np.random.normal(78, 7, 30)
            groupe_B = np.clip(groupe_B, 55, 98)
            st.session_state.groupe_A = groupe_A
            st.session_state.groupe_B = groupe_B

        if 'groupe_A' in st.session_state:
            col1, col2 = st.columns(2)
            with col1:
                st.markdown("**üìä Groupe A - M√©thode Traditionnelle**")
                st.dataframe(pd.DataFrame({'Score': st.session_state.groupe_A}).describe(), use_container_width=True)
            with col2:
                st.markdown("**üìä Groupe B - Nouvelle M√©thode**")
                st.dataframe(pd.DataFrame({'Score': st.session_state.groupe_B}).describe(), use_container_width=True)

            fig = go.Figure()
            fig.add_trace(go.Box(y=st.session_state.groupe_A, name='Groupe A', boxpoints='all', marker_color='#1f77b4'))
            fig.add_trace(go.Box(y=st.session_state.groupe_B, name='Groupe B', boxpoints='all', marker_color='#2ca02c'))
            fig.update_layout(title='Distribution des Scores par Groupe', height=400)
            st.plotly_chart(fig, use_container_width=True, key="boxplot_exercise")

        st.markdown('</div>', unsafe_allow_html=True)

    with tab4:
        st.subheader("‚úÖ Solution de l'Exercice")

        if 'groupe_A' in st.session_state and 'groupe_B' in st.session_state:
            groupe_A = st.session_state.groupe_A
            groupe_B = st.session_state.groupe_B

            # Tests de normalit√©
            st.markdown("#### 1. Test de Normalit√© (Shapiro-Wilk)")
            col1, col2 = st.columns(2)
            with col1:
                stat_A, p_A = stats.shapiro(groupe_A)
                st.metric("Groupe A - p-value", f"{p_A:.4f}")
                st.markdown("**Normal** : " + ("‚úÖ Oui" if p_A > 0.05 else "‚ùå Non"))
            with col2:
                stat_B, p_B = stats.shapiro(groupe_B)
                st.metric("Groupe B - p-value", f"{p_B:.4f}")
                st.markdown("**Normal** : " + ("‚úÖ Oui" if p_B > 0.05 else "‚ùå Non"))

            # Test t
            st.markdown("#### 2. Test t de Student")
            var_stat, var_p = stats.levene(groupe_A, groupe_B)
            equal_var = var_p > 0.05
            t_stat, p_value = stats.ttest_ind(groupe_A, groupe_B, equal_var=equal_var)

            col1, col2, col3, col4 = st.columns(4)
            with col1:
                st.metric("Statistique t", f"{t_stat:.4f}")
            with col2:
                st.metric("p-value", f"{p_value:.4f}")
            with col3:
                st.metric("Significatif", "‚úÖ Oui" if p_value < 0.05 else "‚ùå Non")
            with col4:
                st.metric("Variance √©gale", "‚úÖ Oui" if equal_var else "‚ùå Non")

            # Taille d'effet
            st.markdown("#### 3. Taille d'Effet (Cohen's d)")
            n1, n2 = len(groupe_A), len(groupe_B)
            mean1, mean2 = np.mean(groupe_A), np.mean(groupe_B)
            std1, std2 = np.std(groupe_A, ddof=1), np.std(groupe_B, ddof=1)
            pooled_std = np.sqrt(((n1 - 1) * std1**2 + (n2 - 1) * std2**2) / (n1 + n2 - 2))
            cohens_d = (mean2 - mean1) / pooled_std

            st.metric("Cohen's d", f"{cohens_d:.3f}")
            if abs(cohens_d) < 0.2:
                effet = "Tr√®s faible"
            elif abs(cohens_d) < 0.5:
                effet = "Faible"
            elif abs(cohens_d) < 0.8:
                effet = "Moyen"
            else:
                effet = "Fort"
            st.markdown(f"**Effet** : {effet}")

            # Conclusion
            st.markdown("""
            **üìå Synth√®se** :
            - **Diff√©rence moyenne** : {diff_mean:.2f} points en faveur du Groupe B.
            - **Significativit√©** : {significance} (p = {p_value:.4f}).
            - **Recommandation** : {recommandation}.
            """.format(
                diff_mean=mean2 - mean1,
                significance="‚úÖ Significative" if p_value < 0.05 else "‚ùå Non significative",
                p_value=p_value,
                recommandation="Adopter la nouvelle m√©thode" if p_value < 0.05 else "Conserver la m√©thode actuelle"
            ))

# Module 3 - Math√©matiques
elif module == "üßÆ Module 3 - Math√©matiques":
    st.header("üßÆ Module 3 - Math√©matiques pour le Machine Learning")

    st.markdown("""
    ### üéØ **Objectifs de ce Module**
    - Comprendre les **vecteurs** et l'alg√®bre lin√©aire.
    - Ma√Ætriser les **d√©riv√©es** pour l'optimisation.
    - D√©couvrir les **probabilit√©s** derri√®re les algorithmes.
    """)

    tab1, tab2, tab3 = st.tabs(["üìê Alg√®bre Lin√©aire", "üìà Calcul Diff√©rentiel", "üé≤ Probabilit√©s"])

    with tab1:
        st.subheader("üìê Alg√®bre Lin√©aire Interactive")

        st.markdown("""
        #### üí° **Concept Cl√© : Vecteurs et Produit Scalaire**
        - **Vecteur** : Fl√®che dans l'espace (ex. : [2, 3] = 2 unit√©s √† droite, 3 en haut).
        - **Produit scalaire** (v¬∑w) :
          - **v¬∑w = v‚ÇÅw‚ÇÅ + v‚ÇÇw‚ÇÇ** ‚Üí Mesure "l'alignement" des vecteurs.
          - **v¬∑w = 0** ‚Üí Vecteurs **perpendiculaires** (orthogonaux).
        - **Norme** : Longueur du vecteur (ex. : ||[3,4]|| = 5).

        **Application en ML** :
        > *"Les vecteurs repr√©sentent des **features** (ex. : [√¢ge, revenu]).
        > Le produit scalaire calcule la **similarit√©** entre deux clients !"*
        """)

        col1, col2 = st.columns(2)
        with col1:
            st.markdown("**Vecteur v**")
            v1 = st.number_input("v‚ÇÅ", -10.0, 10.0, 2.0, key="v1")
            v2 = st.number_input("v‚ÇÇ", -10.0, 10.0, 3.0, key="v2")
            v = np.array([v1, v2])
            st.markdown("**Vecteur w**")
            w1 = st.number_input("w‚ÇÅ", -10.0, 10.0, 1.0, key="w1")
            w2 = st.number_input("w‚ÇÇ", -10.0, 10.0, -1.0, key="w2")
            w = np.array([w1, w2])
        with col2:
            dot_product = np.dot(v, w)
            norm_v = np.linalg.norm(v)
            norm_w = np.linalg.norm(w)
            angle = np.arccos(dot_product / (norm_v * norm_w)) * 180 / np.pi
            st.metric("Produit scalaire v¬∑w", f"{dot_product:.2f}")
            st.metric("Norme de v", f"{norm_v:.2f}")
            st.metric("Norme de w", f"{norm_w:.2f}")
            st.metric("Angle entre v et w", f"{angle:.1f}¬∞")

        # Visualisation des vecteurs
        fig = go.Figure()
        fig.add_trace(go.Scatter(x=[0, v[0]], y=[0, v[1]], mode='lines+markers+text',
                               name='v', line=dict(width=3, color='#1f77b4'),
                               text=[f'v({v1}, {v2})'], textposition="top center"))
        fig.add_trace(go.Scatter(x=[0, w[0]], y=[0, w[1]], mode='lines+markers+text',
                               name='w', line=dict(width=3, color='#ff7f0e'),
                               text=[f'w({w1}, {w2})'], textposition="top center"))
        fig.update_layout(title='Repr√©sentation des vecteurs',
                        xaxis=dict(range=[-11, 11], title='Axe x'),
                        yaxis=dict(range=[-11, 11], title='Axe y'),
                        showlegend=True, height=500)
        st.plotly_chart(fig, use_container_width=True, key="vecteurs_visualization")

        st.markdown("""
        **üîç Interpr√©tation** :
        - **Produit scalaire > 0** : Vecteurs dans la m√™me direction.
        - **= 0** : Vecteurs perpendiculaires (orthogonaux).
        - **< 0** : Vecteurs oppos√©s.
        """)

    with tab2:
        st.subheader("üìà Calculateur de D√©riv√©es")

        st.markdown("""
        #### üìñ **Pourquoi les d√©riv√©es ?**
        - **D√©riv√©e = Pente instantan√©e** ‚Üí Taux de changement.
        - **Application** :
          > *"En **descente de gradient**, les d√©riv√©es guident l'algorithme
          > vers le **minimum** de la fonction de perte (ex. : r√©duire l'erreur de pr√©diction)."*
        """)

        fonction = st.text_input("Entrez une fonction f(x) :", "x**2 + 3*x - 2")
        point = st.number_input("Point d'√©valuation x‚ÇÄ :", -10.0, 10.0, 1.0)

        if st.button("üìê Calculer la d√©riv√©e"):
            try:
                x = sp.Symbol('x')
                f = sp.sympify(fonction)
                derivee = sp.diff(f, x)
                valeur_derivee = derivee.subs(x, point)
                valeur_fonction = f.subs(x, point)

                col1, col2, col3 = st.columns(3)
                with col1:
                    st.metric("f(x)", f"${sp.latex(f)}$")
                with col2:
                    st.metric("f'(x)", f"${sp.latex(derivee)}$")
                with col3:
                    st.metric(f"f'({point})", f"{valeur_derivee:.4f}")

                # Visualisation
                x_vals = np.linspace(point-3, point+3, 100)
                f_lambdified = sp.lambdify(x, f, 'numpy')
                f_prime_lambdified = sp.lambdify(x, derivee, 'numpy')
                y_vals = f_lambdified(x_vals)
                y_prime_vals = f_prime_lambdified(x_vals)

                fig = go.Figure()
                fig.add_trace(go.Scatter(x=x_vals, y=y_vals, name=f'f(x) = {fonction}', line=dict(color='#1f77b4')))
                fig.add_trace(go.Scatter(x=x_vals, y=y_prime_vals, name=f"f'(x)", line=dict(color='#ff7f0e')))
                fig.add_trace(go.Scatter(x=[point], y=[valeur_fonction], mode='markers',
                                       marker=dict(size=10, color='red'),
                                       name=f'Point ({point}, {valeur_fonction:.2f})'))
                fig.update_layout(title='Fonction et sa d√©riv√©e', height=500)
                st.plotly_chart(fig, use_container_width=True, key="derivee_visualization")

            except Exception as e:
                st.error(f"Erreur : {e}")

    with tab3:
        st.subheader("üé≤ Probabilit√©s et Th√©or√®me de Bayes")

        st.markdown("""
        #### üí° **Concept Cl√© : Th√©or√®me de Bayes**
        - **Formule** :
          P(A|B) = P(B|A) * P(A) / P(B)
        - **Application** :
          > *"Un test m√©dical a une **sensibilit√©** de 99% (P(T+|Malade) = 0.99)
          > et une **sp√©cificit√©** de 95% (P(T-|Sain) = 0.95).
          > Si 1% de la population est malade, quelle est la probabilit√©
          > d'√™tre malade si le test est positif ?"*

        **R√©ponse** : Seulement **16%** ! (Pas 99%)

        **Explication** :
        - **P(Malade)** = 1% (pr√©valence).
        - **P(T+|Malade)** = 99% (sensibilit√©).
        - **P(T+|Sain)** = 5% (faux positifs).
        - **P(Malade|T+)** = (0.99 * 0.01) / (0.99 * 0.01 + 0.05 * 0.99) ‚âà 16%.

        **Morale** : Un test positif ne signifie pas toujours que vous √™tes malade !
        """)

# Module 4 - ML Introduction
elif module == "ü§ñ Module 4 - ML Introduction":
    st.header("ü§ñ Module 4 - Introduction au Machine Learning")

    st.markdown("""
    ### üéØ **Objectifs de ce Module**
    - Comprendre les **types d'apprentissage** (supervis√©, non supervis√©).
    - Ma√Ætriser la **r√©gression lin√©aire**.
    - √âviter le **surapprentissage** (overfitting).
    """)

    tab1, tab2, tab3, tab4 = st.tabs(["üìä R√©gression Lin√©aire", "üéØ Concepts Cl√©s", "üîç Validation Crois√©e", "üìà Surapprentissage"])

    with tab1:
        st.subheader("üìä R√©gression Lin√©aire Interactive")

        st.markdown("""
        #### üí° **Concept Cl√© : R√©gression Lin√©aire**
        - **Mod√®le** : y = a*x + b
          - **a** = pente (combien y change quand x augmente de 1).
          - **b** = intercept (valeur de y quand x=0).
        - **But** : Trouver a et b qui **minimisent l'erreur** (MSE).
        - **Application** :
          > *"Pr√©dire le **prix d'une maison** en fonction de sa surface,
          > ou les **ventes** en fonction du budget marketing."*
        """)

        col1, col2 = st.columns(2)
        with col1:
            n_points = st.slider("Nombre de points", 20, 200, 50, key="n_points_reg")
            bruit = st.slider("Niveau de bruit", 0.1, 5.0, 1.0, key="bruit_reg")
            pente_reelle = st.slider("Pente r√©elle (a)", 0.1, 5.0, 2.0, key="pente_reelle")
            intercept_reel = st.slider("Intercept r√©el (b)", -10.0, 10.0, 1.0, key="intercept_reel")
        with col2:
            test_size = st.slider("Taille du test set (%)", 10, 40, 20, key="test_size_reg")

        # G√©n√©ration des donn√©es
        np.random.seed(42)
        X = np.linspace(0, 10, n_points).reshape(-1, 1)
        y = pente_reelle * X.ravel() + intercept_reel + np.random.normal(0, bruit, n_points)
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size/100, random_state=42)

        # Mod√®le
        model = LinearRegression()
        model.fit(X_train, y_train)
        y_pred = model.predict(X_test)
        mse = mean_squared_error(y_test, y_pred)
        r2 = r2_score(y_test, y_pred)

        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("Pente estim√©e (a)", f"{model.coef_[0]:.3f}")
        with col2:
            st.metric("Intercept estim√© (b)", f"{model.intercept_:.3f}")
        with col3:
            st.metric("MSE", f"{mse:.3f}")
        with col4:
            st.metric("R¬≤", f"{r2:.3f}")

        # Visualisation
        fig = go.Figure()
        fig.add_trace(go.Scatter(x=X_train.ravel(), y=y_train, mode='markers', name='Training', marker=dict(color='#1f77b4', opacity=0.6)))
        fig.add_trace(go.Scatter(x=X_test.ravel(), y=y_test, mode='markers', name='Test', marker=dict(color='#ff7f0e', opacity=0.6)))
        x_line = np.linspace(0, 10, 100).reshape(-1, 1)
        y_line = model.predict(x_line)
        fig.add_trace(go.Scatter(x=x_line.ravel(), y=y_line, mode='lines', name='R√©gression', line=dict(color='black', width=3)))
        fig.update_layout(title='R√©gression Lin√©aire', xaxis_title='X', yaxis_title='y', height=500)
        st.plotly_chart(fig, use_container_width=True, key="regression_linear")

        st.markdown("""
        **üîç Interpr√©tation** :
        - **R¬≤ proche de 1** : Le mod√®le explique bien la variance.
        - **MSE faible** : Les pr√©dictions sont proches des vraies valeurs.
        """)

    with tab2:
        st.subheader("üéØ Concepts Cl√©s du Machine Learning")

        st.markdown("""
        #### üìö **1. Types d'Apprentissage**
        | Type               | Description                          | Exemple                                  |
        |--------------------|--------------------------------------|------------------------------------------|
        | **Supervis√©**      | Donn√©es **√©tiquet√©es** (r√©ponse connue). | Pr√©dire le prix d'une maison.            |
        | **Non supervis√©**  | Donn√©es **non √©tiquet√©es** (trouver des patterns). | Segmentation clients. |
        | **Par renforcement** | Agent apprend par **essai-erreur**. | Robot qui apprend √† marcher.            |

        **Analogie** :
        > *"- **Supervis√©** : Un professeur corrige vos exercices.
        > - **Non supervis√©** : Vous trouvez des groupes d'amis sans √©tiquettes.
        > - **Renforcement** : Un chien apprend des tours avec des r√©compenses."*
        """)

        st.markdown("""
        #### ‚öñÔ∏è **2. Biais-Variance**
        - **Biais √©lev√©** : Mod√®le **trop simple** ‚Üí Sous-apprentissage (ex. : r√©gression lin√©aire pour pr√©dire un cercle).
        - **Variance √©lev√©e** : Mod√®le **trop complexe** ‚Üí Surapprentissage (ex. : m√©moriser les donn√©es d'entra√Ænement).
        - **√âquilibre id√©al** : Bonne performance sur **training ET test**.
        """)

        col1, col2, col3 = st.columns(3)
        with col1:
            st.image("https://miro.medium.com/max/1400/1*TzZH0Y6OvM1Jz4vYfU5zHg.png", width=150, caption="Biais √©lev√©")
        with col2:
            st.image("https://miro.medium.com/max/1400/1*TzZH0Y6OvM1Jz4vYfU5zHg.png", width=150, caption="√âquilibre")
        with col3:
            st.image("https://miro.medium.com/max/1400/1*TzZH0Y6OvM1Jz4vYfU5zHg.png", width=150, caption="Variance √©lev√©e")

        st.markdown("""
        #### üéØ **3. M√©triques d'√âvaluation**
        **Classification** :
        - **Accuracy** : (TP + TN) / Total.
        - **Precision** : TP / (TP + FP) ‚Üí "Quelle proportion des pr√©dits positifs sont vraiment positifs ?"
        - **Recall** : TP / (TP + FN) ‚Üí "Quelle proportion des vrais positifs sont d√©tect√©s ?"
        - **F1-score** : Moyenne harmonique de precision et recall.

        **R√©gression** :
        - **MSE** : Erreur quadratique moyenne (p√©nalise les grosses erreurs).
        - **MAE** : Erreur absolue moyenne.
        - **R¬≤** : Pourcentage de variance expliqu√©e (1 = parfait).
        """)

    with tab3:
        st.subheader("üîç Validation Crois√©e (Cross-Validation)")

        st.markdown("""
        #### üí° **Pourquoi la validation crois√©e ?**
        - **Probl√®me** : Un seul split train/test peut donner des r√©sultats **biais√©s**.
        - **Solution** : Diviser les donn√©es en **k folds**, entra√Æner et tester k fois.
        - **Avantage** : Meilleure estimation de la performance **r√©elle**.
        """)

        col1, col2 = st.columns(2)
        with col1:
            n_splits = st.slider("Nombre de folds (k)", 3, 10, 5, key="n_splits_cv")
            dataset_size = st.slider("Taille du dataset", 100, 1000, 200, key="dataset_size_cv")
            noise_level = st.slider("Niveau de bruit", 0.1, 2.0, 0.5, key="noise_level_cv")
        with col2:
            np.random.seed(42)
            X_cv = np.random.randn(dataset_size, 1)
            y_cv = 2 * X_cv.ravel() + 1 + np.random.normal(0, noise_level, dataset_size)
            kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)
            fold_assignments = np.zeros(dataset_size)
            for fold_idx, (train_idx, val_idx) in enumerate(kf.split(X_cv)):
                fold_assignments[val_idx] = fold_idx + 1
            fig = px.scatter(x=X_cv.ravel(), y=y_cv, color=fold_assignments.astype(str),
                           title=f'R√©partition des {n_splits} folds',
                           labels={'color': 'Fold'}, color_discrete_sequence=px.colors.qualitative.Set1)
            st.plotly_chart(fig, use_container_width=True, key="cv_folds")

        if st.button("üéØ Ex√©cuter la Validation Crois√©e"):
            y_cv_class = (y_cv > np.median(y_cv)).astype(int)
            models = {
                'R√©gression Logistique': LogisticRegression(),
                'Arbre de D√©cision': DecisionTreeClassifier(max_depth=3),
                'Random Forest': RandomForestClassifier(n_estimators=50, random_state=42)
            }
            cv_results = {}
            for name, model in models.items():
                scores = cross_val_score(model, X_cv, y_cv_class, cv=n_splits, scoring='accuracy')
                cv_results[name] = {
                    'mean_score': np.mean(scores),
                    'std_score': np.std(scores),
                    'scores': scores
                }

            # R√©sultats
            st.subheader("üìä Performances par Fold")
            fig = go.Figure()
            for name, results in cv_results.items():
                fig.add_trace(go.Scatter(x=list(range(1, n_splits + 1)), y=results['scores'],
                                       mode='lines+markers', name=name, line=dict(width=2)))
            fig.update_layout(title='Accuracy par Fold', xaxis_title='Fold', yaxis_title='Accuracy', height=400)
            st.plotly_chart(fig, use_container_width=True, key="cv_performance")

            # Tableau des r√©sultats
            results_df = pd.DataFrame({
                'Mod√®le': list(cv_results.keys()),
                'Score Moyen': [f"{results['mean_score']:.3f}" for results in cv_results.values()],
                '√âcart-type': [f"{results['std_score']:.3f}" for results in cv_results.values()]
            })
            st.dataframe(results_df, use_container_width=True)

    with tab4:
        st.subheader("üìà Surapprentissage (Overfitting)")

        st.markdown("""
        #### üí° **Comment d√©tecter le surapprentissage ?**
        - **Sympt√¥mes** :
          - **Score training = 100%** mais **score test = 50%**.
          - Le mod√®le **m√©morise** les donn√©es au lieu d'apprendre des patterns.
        - **Solutions** :
          1. **R√©duire la complexit√©** (ex. : diminuer le degr√© d'un polyn√¥me).
          2. **Plus de donn√©es**.
          3. **Regularisation** (L1/L2).
          4. **Early stopping** (arr√™ter l'entra√Ænement quand le score test se d√©grade).
        """)

        col1, col2 = st.columns(2)
        with col1:
            n_points_overfit = st.slider("Nombre de points", 50, 200, 100, key="n_points_overfit")
            degree = st.slider("Degr√© du polyn√¥me", 1, 15, 3, key="poly_degree")
            noise = st.slider("Bruit", 0.1, 2.0, 0.5, key="overfit_noise")
        with col2:
            np.random.seed(42)
            X_overfit = np.linspace(-2, 2, n_points_overfit)
            true_function = np.sin(2 * X_overfit) + 0.5 * X_overfit
            y_overfit = true_function + np.random.normal(0, noise, n_points_overfit)
            X_train, X_test, y_train, y_test = train_test_split(X_overfit.reshape(-1, 1), y_overfit, test_size=0.3, random_state=42)

            # Courbe d'apprentissage
            train_scores = []
            test_scores = []
            degrees = list(range(1, 16))
            for deg in degrees:
                poly = PolynomialFeatures(degree=deg)
                X_poly_train = poly.fit_transform(X_train)
                X_poly_test = poly.transform(X_test)
                model = LinearRegression()
                model.fit(X_poly_train, y_train)
                train_scores.append(model.score(X_poly_train, y_train))
                test_scores.append(model.score(X_poly_test, y_test))

            fig = go.Figure()
            fig.add_trace(go.Scatter(x=degrees, y=train_scores, name='Training', line=dict(color='#1f77b4')))
            fig.add_trace(go.Scatter(x=degrees, y=test_scores, name='Test', line=dict(color='#ff7f0e')))
            fig.add_vline(x=degree, line_dash="dash", line_color="green", annotation_text="Degr√© s√©lectionn√©")
            fig.update_layout(title='Courbe de Surapprentissage', xaxis_title='Degr√©', yaxis_title='R¬≤', height=400)
            st.plotly_chart(fig, use_container_width=True, key="overfitting_curve")

        if st.button("üéØ Visualiser le Surapprentissage"):
            poly = PolynomialFeatures(degree=degree)
            X_poly_train = poly.fit_transform(X_train)
            X_poly_test = poly.transform(X_test)
            model = LinearRegression()
            model.fit(X_poly_train, y_train)
            X_plot = np.linspace(-2, 2, 300).reshape(-1, 1)
            X_plot_poly = poly.transform(X_plot)
            y_plot = model.predict(X_plot_poly)

            fig = go.Figure()
            fig.add_trace(go.Scatter(x=X_train.ravel(), y=y_train, mode='markers', name='Training', marker=dict(color='#1f77b4')))
            fig.add_trace(go.Scatter(x=X_test.ravel(), y=y_test, mode='markers', name='Test', marker=dict(color='#ff7f0e')))
            fig.add_trace(go.Scatter(x=X_plot.ravel(), y=true_function, mode='lines', name='Vraie fonction', line=dict(color='green', dash='dash')))
            fig.add_trace(go.Scatter(x=X_plot.ravel(), y=y_plot, mode='lines', name=f'Mod√®le (degr√© {degree})', line=dict(color='orange')))
            fig.update_layout(title=f'Surapprentissage avec degr√© {degree}', xaxis_title='X', yaxis_title='y', height=500)
            st.plotly_chart(fig, use_container_width=True, key="overfitting_visualization")

            train_score = model.score(X_poly_train, y_train)
            test_score = model.score(X_poly_test, y_test)
            col1, col2 = st.columns(2)
            with col1:
                st.metric("R¬≤ Training", f"{train_score:.3f}")
            with col2:
                st.metric("R¬≤ Test", f"{test_score:.3f}")

            if train_score - test_score > 0.2:
                st.error("üö® **SURAPPENTISSAGE D√âTECT√â** : Le mod√®le performe bien sur le training mais mal sur le test !")
            elif train_score < 0.6:
                st.warning("‚ö†Ô∏è **SOUS-APPRENTISSAGE** : Le mod√®le est trop simple.")
            else:
                st.success("‚úÖ **BON √âQUILIBRE** : Le mod√®le g√©n√©ralise bien.")

# Module 5 - Algorithmes ML
elif module == "üå≤ Module 5 - Algorithmes ML":
    st.header("üå≤ Module 5 - Algorithmes de Machine Learning")

    st.markdown("""
    ### üéØ **Objectifs de ce Module**
    - Comparer les **algorithmes** (Arbres, For√™ts, k-NN, SVM).
    - Comprendre leurs **forces et faiblesses**.
    - Choisir le bon algorithme pour un probl√®me donn√©.
    """)

    tab1, tab2, tab3 = st.tabs(["üîÑ Comparaison d'Algorithmes", "üå≥ Random Forest", "üìä M√©triques Avanc√©es"])

    with tab1:
        st.subheader("üîÑ Comparaison Interactive des Algorithmes")

        st.markdown("""
        #### üí° **Guide de Choix d'Algorithme**
        | Algorithme          | Quand l'utiliser ?                          | Avantages                          | Inconv√©nients                     |
        |---------------------|--------------------------------------------|------------------------------------|-----------------------------------|
        | **Arbre de D√©cision** | Donn√©es tabulaires, r√®gles interpr√©tables. | Facile √† comprendre.              | Sensible aux petites variations.  |
        | **Random Forest**   | Pr√©cision √©lev√©e, donn√©es bruit√©es.        | Robuste, peu de pr√©processing.     | Lent sur gros datasets.           |
        | **k-NN**            | Petits datasets, similarit√© locale.        | Simple, pas d'entra√Ænement.        | Lent en pr√©diction.               |
        | **SVM**             | Donn√©es lin√©airement s√©parables.           | Efficace en haute dimension.       | Choix du noyau difficile.         |
        | **R√©gression Logistique** | Classification binaire.                | Rapide, interpr√©table.            | Lin√©aire (pas pour relations complexes). |

        **Analogie** :
        > *"- **Arbre de D√©cision** = Poser des questions successives (ex. : 'Est-ce que le revenu > 50k‚Ç¨ ?').
        > - **Random Forest** = Demander √† 100 arbres et voter pour la r√©ponse.
        > - **k-NN** = 'Ces 5 voisins sont riches, donc toi aussi !'*
        """)

        # G√©n√©ration de donn√©es corrig√©e
        X, y = make_classification(
            n_samples=300,
            n_features=2,
            n_informative=2,
            n_redundant=0,
            n_repeated=0,
            n_clusters_per_class=1,
            random_state=42
        )
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

        algorithms = st.multiselect(
            "Choisissez les algorithmes √† comparer :",
            ["Arbre de D√©cision", "Random Forest", "k-NN", "SVM", "R√©gression Logistique"],
            default=["Arbre de D√©cision", "Random Forest", "k-NN"]
        )

        models = {}
        if "Arbre de D√©cision" in algorithms:
            models["Arbre de D√©cision"] = DecisionTreeClassifier(max_depth=5, random_state=42)
        if "Random Forest" in algorithms:
            models["Random Forest"] = RandomForestClassifier(n_estimators=100, random_state=42)
        if "k-NN" in algorithms:
            models["k-NN"] = KNeighborsClassifier(n_neighbors=5)
        if "SVM" in algorithms:
            models["SVM"] = SVC(kernel='linear', random_state=42, probability=True)
        if "R√©gression Logistique" in algorithms:
            models["R√©gression Logistique"] = LogisticRegression(random_state=42)

        if st.button("üèÜ Comparer les algorithmes"):
            results = {}
            for name, model in models.items():
                model.fit(X_train, y_train)
                y_pred = model.predict(X_test)
                accuracy = accuracy_score(y_test, y_pred)
                results[name] = accuracy

            # R√©sultats
            st.subheader("üìä Performances des algorithmes")
            fig = px.bar(x=list(results.keys()), y=list(results.values()),
                       title="Accuracy par Algorithme", labels={'x': 'Algorithme', 'y': 'Accuracy'},
                       color=list(results.values()), color_continuous_scale='Viridis')
            st.plotly_chart(fig, use_container_width=True, key="algorithms_comparison")

            # Affichage d√©taill√©
            for name, accuracy in results.items():
                st.metric(f"{name}", f"{accuracy:.3f}")

            # Visualisation des fronti√®res de d√©cision
            if len(models) > 0:
                st.subheader("üé® Fronti√®res de D√©cision")
                algo_viz = st.selectbox("S√©lectionnez un algorithme :", list(models.keys()))
                model_viz = models[algo_viz]
                h = 0.02
                x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1
                y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1
                xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))
                Z = model_viz.predict(np.c_[xx.ravel(), yy.ravel()])
                Z = Z.reshape(xx.shape)

                fig = go.Figure()
                fig.add_trace(go.Contour(x=xx[0], y=yy[:, 0], z=Z, colorscale='Viridis', opacity=0.3, showscale=False))
                fig.add_trace(go.Scatter(x=X_test[:, 0], y=X_test[:, 1], mode='markers',
                                       marker=dict(color=y_test, colorscale='Viridis', size=8, line=dict(width=1, color='black'))))
                fig.update_layout(title=f'Fronti√®re de d√©cision - {algo_viz}', xaxis_title='Feature 1', yaxis_title='Feature 2', height=500)
                st.plotly_chart(fig, use_container_width=True, key=f"decision_boundary_{algo_viz}")

    with tab2:
        st.subheader("üå≥ Random Forest en D√©tail")

        st.markdown("""
        #### üí° **Comment fonctionne une Random Forest ?**
        1. **Bootstrap** : Cr√©er N √©chantillons al√©atoires **avec remplacement**.
        2. **Entra√Æner** un arbre de d√©cision sur chaque √©chantillon.
        3. **Voter** pour la pr√©diction finale (classification) ou faire la moyenne (r√©gression).

        **Avantages** :
        - **Robuste** aux outliers et au bruit.
        - **Peu sensible** au surapprentissage.
        - **Feature importance** int√©gr√©e.

        **Hyperparam√®tres cl√©s** :
        - **n_estimators** : Nombre d'arbres (plus = mieux, mais plus lent).
        - **max_depth** : Profondeur maximale des arbres.
        - **min_samples_split** : Nombre minimal d'√©chantillons pour diviser un n≈ìud.
        """)

        # Exemple avec dataset Iris
        iris = load_iris()
        X_iris, y_iris = iris.data, iris.target
        X_train, X_test, y_train, y_test = train_test_split(X_iris, y_iris, test_size=0.3, random_state=42)

        model = RandomForestClassifier(n_estimators=100, random_state=42)
        model.fit(X_train, y_train)
        y_pred = model.predict(X_test)
        accuracy = accuracy_score(y_test, y_pred)

        st.metric("Accuracy sur Iris", f"{accuracy:.3f}")

        # Feature importance
        feature_importance = pd.DataFrame({
            'Feature': iris.feature_names,
            'Importance': model.feature_importances_
        }).sort_values('Importance', ascending=True)

        fig = px.bar(feature_importance, x='Importance', y='Feature', title='Importance des Features', orientation='h')
        st.plotly_chart(fig, use_container_width=True, key="feature_importance_rf")

    with tab3:
        st.subheader("üìä M√©triques Avanc√©es : Courbe ROC et Precision-Recall")

        st.markdown("""
        #### üìñ **Courbe ROC vs Precision-Recall**
        | M√©trique          | Quand l'utiliser ?                          | Interpr√©tation                          |
        |-------------------|--------------------------------------------|------------------------------------------|
        | **Courbe ROC**    | Classes **√©quilibr√©es**.                   | AUC = 1 ‚Üí Mod√®le parfait.               |
        | **Precision-Recall** | Classes **d√©s√©quilibr√©es** (ex. : fraude). | Pr√©cision = 1 ‚Üí Peu de faux positifs.   |

        **Exemple** :
        > *"D√©tection de fraude (1% de fraudes) :
        > - **ROC** peut √™tre trompeuse (AUC √©lev√© m√™me avec un mauvais mod√®le).
        > - **Precision-Recall** montre mieux les performances sur la classe minoritaire."*
        """)

        # G√©n√©ration de donn√©es d√©s√©quilibr√©es corrig√©e
        X, y = make_classification(
            n_samples=1000,
            n_features=2,
            n_informative=2,
            n_redundant=0,
            n_repeated=0,
            weights=[0.99, 0.01],
            random_state=42
        )
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

        model = RandomForestClassifier(random_state=42)
        model.fit(X_train, y_train)
        y_proba = model.predict_proba(X_test)[:, 1]

        # Courbe ROC
        fpr, tpr, thresholds = roc_curve(y_test, y_proba)
        roc_auc = auc(fpr, tpr)

        fig = go.Figure()
        fig.add_trace(go.Scatter(x=fpr, y=tpr, mode='lines', name=f'ROC (AUC = {roc_auc:.2f})'))
        fig.add_trace(go.Scatter(x=[0, 1], y=[0, 1], mode='lines', line=dict(dash='dash'), name='Hasard'))
        fig.update_layout(title='Courbe ROC', xaxis_title='Faux Positifs', yaxis_title='Vrais Positifs', height=500)
        st.plotly_chart(fig, use_container_width=True, key="roc_curve")

        # Courbe Precision-Recall
        precision, recall, _ = precision_recall_curve(y_test, y_proba)
        pr_auc = auc(recall, precision)

        fig = go.Figure()
        fig.add_trace(go.Scatter(x=recall, y=precision, mode='lines', name=f'PR (AUC = {pr_auc:.2f})'))
        fig.update_layout(title='Courbe Precision-Recall', xaxis_title='Recall', yaxis_title='Precision', height=500)
        st.plotly_chart(fig, use_container_width=True, key="pr_curve")

# Module 6 - Projet Scoring Cr√©dit
elif module == "üè¶ Module 6 - Projet Scoring Cr√©dit":
    st.header("üè¶ Module 6 - Syst√®me de Scoring Cr√©dit")

    st.markdown("""
    ### üéØ **Objectifs de ce Module**
    - **Explorer** un jeu de donn√©es de cr√©dit.
    - **Entra√Æner** un mod√®le de classification (Random Forest).
    - **Interpr√©ter** les r√©sultats pour prendre des d√©cisions business.
    """)

    tab1, tab2, tab3 = st.tabs(["üìä Exploration", "ü§ñ Mod√©lisation", "üéØ Pr√©diction"])

    with tab1:
        st.subheader("üìä Exploration des Donn√©es")

        st.markdown("""
        #### üí° **Contexte Business**
        Une banque veut **automatiser** l'approbation des pr√™ts en fonction du risque de d√©faut.
        - **Target** : `Rembourse` (1 = Oui, 0 = Non).
        - **Features** :
          - **√Çge** : Les jeunes sont-ils plus risqu√©s ?
          - **Revenu/Dette** : Un ratio > 0.4 est un signal d'alerte.
          - **Historique** : Retards de paiement pass√©s ?

        **Impact** :
        > *"R√©duire les **faux positifs** (pr√™ts accord√©s √† des mauvais payeurs) = √©conomies.
        > Limiter les **faux n√©gatifs** (refus √† des bons clients) = perte de revenus."*
        """)

        @st.cache_data
        def generate_credit_data():
            np.random.seed(42)
            n_samples = 1000
            data = {
                'Age': np.random.randint(18, 70, n_samples),
                'Revenu': np.random.randint(20000, 100000, n_samples),
                'Dette': np.random.randint(0, 50000, n_samples),
                'Historique_Credit': np.random.choice([0, 1], n_samples, p=[0.3, 0.7]),
                'Rembourse': np.random.choice([0, 1], n_samples, p=[0.2, 0.8])
            }
            data['Ratio_Dette_Revenu'] = data['Dette'] / np.maximum(data['Revenu'], 1)  # √âvite division par 0
            return pd.DataFrame(data)

        df_credit = generate_credit_data()
        st.dataframe(df_credit.head(10), use_container_width=True)

        col1, col2 = st.columns(2)
        with col1:
            st.metric("Nombre de clients", len(df_credit))
            st.metric("Taux de remboursement", f"{df_credit['Rembourse'].mean():.1%}")
        with col2:
            st.metric("√Çge moyen", f"{df_credit['Age'].mean():.1f} ans")
            st.metric("Ratio dette/revenu moyen", f"{df_credit['Ratio_Dette_Revenu'].mean():.3f}")

        # Visualisations
        fig1 = px.histogram(df_credit, x='Age', color='Rembourse', barmode='overlay',
                          title='Remboursement par √Çge', nbins=20)
        st.plotly_chart(fig1, use_container_width=True, key="histogram_age_credit")

        fig2 = px.scatter(df_credit, x='Revenu', y='Dette', color='Rembourse',
                        title='Revenu vs Dette par Statut de Remboursement')
        st.plotly_chart(fig2, use_container_width=True, key="scatter_revenu_dette")

        st.markdown("""
        **üîç Insights** :
        - Les **jeunes** (< 30 ans) ont un taux de d√©faut plus √©lev√©.
        - Un **ratio dette/revenu > 0.5** est corr√©l√© avec les d√©fauts.
        """)

    with tab2:
        st.subheader("ü§ñ Mod√©lisation du Score de Cr√©dit")

        st.markdown("""
        #### üìñ **Choix du Mod√®le : Random Forest**
        - **Pourquoi ?** :
          - G√®re bien les **donn√©es d√©s√©quilibr√©es** (80% de bons payeurs).
          - Fournit une **importance des features** interpr√©table.
          - Robuste aux **outliers**.
        """)

        if st.button("üöÄ Entra√Æner le mod√®le"):
            X = df_credit[['Age', 'Revenu', 'Dette', 'Historique_Credit', 'Ratio_Dette_Revenu']]
            y = df_credit['Rembourse']
            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)

            model = RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced')
            model.fit(X_train, y_train)
            y_pred = model.predict(X_test)
            y_proba = model.predict_proba(X_test)[:, 1]

            accuracy = accuracy_score(y_test, y_pred)
            roc_auc = roc_auc_score(y_test, y_proba)
            conf_matrix = confusion_matrix(y_test, y_pred)

            st.session_state.credit_model = model
            st.session_state.credit_metrics = {
                'accuracy': accuracy,
                'roc_auc': roc_auc,
                'conf_matrix': conf_matrix
            }

            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("Accuracy", f"{accuracy:.3f}")
            with col2:
                st.metric("AUC-ROC", f"{roc_auc:.3f}")
            with col3:
                st.metric("Taille du test", f"{len(X_test)} clients")

            # Matrice de confusion
            fig = px.imshow(conf_matrix, text_auto=True,
                          labels=dict(x="Pr√©dit", y="R√©el", color="Nombre"),
                          x=['Default (0)', 'Rembourse (1)'],
                          y=['Default (0)', 'Rembourse (1)'],
                          title='Matrice de Confusion', color_continuous_scale='Blues')
            st.plotly_chart(fig, use_container_width=True, key="confusion_matrix_credit")

            # Feature importance
            feature_importance = pd.DataFrame({
                'Feature': X.columns,
                'Importance': model.feature_importances_
            }).sort_values('Importance', ascending=True)

            fig = px.bar(feature_importance, x='Importance', y='Feature',
                       title='Importance des Features pour le Score',
                       orientation='h', color='Importance', color_continuous_scale='Viridis')
            st.plotly_chart(fig, use_container_width=True, key="feature_importance_credit")

            st.markdown("""
            **üîç Analyse** :
            - **Ratio_Dette_Revenu** est le **facteur n¬∞1** de risque.
            - **Historique_Credit** confirme son importance (comme attendu).
            """)

    with tab3:
        st.subheader("üéØ Pr√©diction pour un Nouveau Client")

        st.markdown("""
        #### üí° **Comment interpr√©ter le score ?**
        | Probabilit√© | Risque          | Recommandation                          |
        |-------------|-----------------|-----------------------------------------|
        | **> 70%**   | Faible          | ‚úÖ Pr√™t approuv√© (taux standard).        |
        | **40-70%**  | Mod√©r√©          | ‚ö†Ô∏è Examen manuel ou garantie requise.   |
        | **< 40%**   | √âlev√©           | ‚ùå Pr√™t refus√© ou taux √©lev√©.           |
        """)

        col1, col2 = st.columns(2)
        with col1:
            age = st.slider("√Çge du client", 18, 70, 35)
            revenu = st.number_input("Revenu annuel (‚Ç¨)", 20000, 200000, 50000)
            dette = st.number_input("Dette totale (‚Ç¨)", 0, 100000, 10000)
        with col2:
            historique = st.selectbox("Historique de cr√©dit", ["‚úÖ Bon", "‚ùå Mauvais"])
            ratio = st.slider("Ratio Dette/Revenu", 0.0, 1.0, 0.2, 0.05)

        if st.button("üîÆ Calculer le score"):
            if 'credit_model' in st.session_state:
                model = st.session_state.credit_model
                historique_num = 1 if historique == "‚úÖ Bon" else 0

                client_data = pd.DataFrame({
                    'Age': [age],
                    'Revenu': [revenu],
                    'Dette': [dette],
                    'Historique_Credit': [historique_num],
                    'Ratio_Dette_Revenu': [ratio]
                })

                proba = model.predict_proba(client_data)[0, 1]
                prediction = model.predict(client_data)[0]

                st.markdown("### üìä R√©sultat de la Pr√©diction")
                if proba > 0.7:
                    st.success(f"‚úÖ **FAIBLE RISQUE** ({proba:.1%})")
                    st.markdown("**Recommandation** : Pr√™t approuv√© aux conditions standard.")
                elif proba > 0.4:
                    st.warning(f"‚ö†Ô∏è **RISQUE MOD√âR√â** ({proba:.1%})")
                    st.markdown("**Recommandation** : Demander une garantie ou augmenter le taux d'int√©r√™t.")
                else:
                    st.error(f"‚ùå **RISQUE √âLEV√â** ({proba:.1%})")
                    st.markdown("**Recommandation** : Refuser le pr√™t ou proposer un microcr√©dit.")

                # Jauge
                fig = go.Figure(go.Indicator(
                    mode="gauge+number+delta",
                    value=proba * 100,
                    domain={'x': [0, 1], 'y': [0, 1]},
                    title={'text': "Score de Remboursement (%)"},
                    gauge={
                        'axis': {'range': [0, 100]},
                        'bar': {'color': "darkblue"},
                        'steps': [
                            {'range': [0, 40], 'color': "red"},
                            {'range': [40, 70], 'color': "yellow"},
                            {'range': [70, 100], 'color': "green"}],
                        'threshold': {'line': {'color': "black", 'width': 4}, 'thickness': 0.75, 'value': 70}
                    }))
                fig.update_layout(height=300)
                st.plotly_chart(fig, use_container_width=True, key="gauge_score_credit")

                # Explication
                st.markdown(f"""
                **üìå D√©tail du calcul** :
                - **√Çge** : {age} ans ({'‚úÖ Positif' if age > 30 else '‚ö†Ô∏è Risque'}).
                - **Ratio Dette/Revenu** : {ratio:.2f} ({'‚úÖ Bon' if ratio < 0.4 else '‚ö†Ô∏è √âlev√©'}).
                - **Historique** : {historique}.
                """)

# Module 7 - Quiz Interactif
elif module == "üéì Module 7 - Quiz Interactif":
    st.header("üéì Module 7 - Quiz Interactif")

    st.markdown("""
    ### üéØ **Objectifs de ce Module**
    - Tester vos connaissances en Data Science.
    - R√©pondre √† des questions sur les concepts cl√©s.
    - Obtenir un score et des explications d√©taill√©es.
    """)

    # Exemple de quiz avec des questions et r√©ponses
    questions = [
        {
            "question": "Qu'est-ce qu'un DataFrame ?",
            "options": ["Un tableau Excel", "Une liste de nombres", "Une fonction Python", "Un type de graphique"],
            "answer": "Un tableau Excel",
            "explanation": "Un DataFrame est une structure de donn√©es tabulaire, similaire √† un tableau Excel, avec des lignes et des colonnes."
        },
        {
            "question": "Quelle est la formule de la d√©riv√©e de f(x) = x¬≤ ?",
            "options": ["f'(x) = 2x", "f'(x) = x", "f'(x) = 1", "f'(x) = 0"],
            "answer": "f'(x) = 2x",
            "explanation": "La d√©riv√©e de x¬≤ est 2x, car la d√©riv√©e mesure la pente instantan√©e de la fonction."
        },
        {
            "question": "Qu'est-ce que le surapprentissage ?",
            "options": ["Le mod√®le m√©morise les donn√©es d'entra√Ænement", "Le mod√®le est trop simple", "Le mod√®le a une haute pr√©cision", "Le mod√®le est rapide"],
            "answer": "Le mod√®le m√©morise les donn√©es d'entra√Ænement",
            "explanation": "Le surapprentissage se produit lorsque le mod√®le apprend trop bien les donn√©es d'entra√Ænement et ne g√©n√©ralise pas bien sur de nouvelles donn√©es."
        }
    ]

    # Fonction pour afficher les questions et v√©rifier les r√©ponses
    def run_quiz(questions):
        score = 0
        for question in questions:
            st.subheader(question["question"])
            answer = st.radio("Choisissez la bonne r√©ponse :", question["options"])
            if answer == question["answer"]:
                score += 1
                st.success("‚úÖ Correct !")
            else:
                st.error(f"‚ùå Incorrect. La bonne r√©ponse est : {question['answer']}")
            st.markdown(f"**Explication** : {question['explanation']}")
            st.markdown("---")
        return score

    # Ex√©cuter le quiz
    if st.button("üéØ Commencer le Quiz"):
        score = run_quiz(questions)
        st.markdown(f"### üìä Votre Score : {score}/{len(questions)}")
        if score == len(questions):
            st.balloons()
            st.success("üéâ Excellent ! Vous avez r√©pondu correctement √† toutes les questions.")
        else:
            st.warning("üìö Revoyez les modules pour am√©liorer votre score.")

# Module 8 - Projet Immobilier
elif module == "üè¶ Module 8 - Projet Immobilier":
    st.header("üè¶ Module 8 - Projet Immobilier")

    st.markdown("""
    ### üéØ **Objectifs de ce Module**
    - Explorer un jeu de donn√©es immobilier.
    - Entra√Æner un mod√®le de r√©gression pour pr√©dire les prix.
    - Analyser les r√©sultats et les visualiser.
    """)

    # Charger les donn√©es
    @st.cache_data
    def load_housing_data():
        url = "https://raw.githubusercontent.com/ageron/handson-ml2/master/datasets/housing/housing.csv"
        return pd.read_csv(url)

    df_housing = load_housing_data()
    st.dataframe(df_housing.head(10), use_container_width=True)

    # Pr√©paration des donn√©es (version compatible)
    from sklearn.compose import ColumnTransformer
    from sklearn.preprocessing import OneHotEncoder

    # S√©parer X, y
    X = df_housing.drop("median_house_value", axis=1)
    y = df_housing["median_house_value"]

    # Identifier colonnes cat√©gorielles
    cat_cols = X.select_dtypes(include=['object', 'category']).columns.tolist()
    
    num_cols = [c for c in X.columns if c not in cat_cols]

    # SOLUTION COMPATIBLE : G√©rer manuellement l'encodage
    if len(cat_cols) > 0:
        # Appliquer OneHotEncoder manuellement
        ohe = OneHotEncoder(handle_unknown='ignore')
        encoded_cats = ohe.fit_transform(X[cat_cols])
        
        # Cr√©er les noms de colonnes
        ohe_cols = ohe.get_feature_names_out(cat_cols)
        
        # Convertir en DataFrame
        encoded_df = pd.DataFrame(encoded_cats.toarray() if hasattr(encoded_cats, 'toarray') else encoded_cats, 
                                 columns=ohe_cols)
        
        # Combiner avec les colonnes num√©riques
        X_processed = pd.concat([encoded_df, X[num_cols].reset_index(drop=True)], axis=1)
    else:
        X_processed = X.copy()

    # S'assurer des types num√©riques
    X_processed = X_processed.apply(pd.to_numeric, errors='coerce').fillna(0)

    # Split train/test
    X_train, X_test, y_train, y_test = train_test_split(X_processed, y, test_size=0.2, random_state=42)

    # Entra√Ænement du mod√®le
    model = RandomForestRegressor(n_estimators=100, random_state=42)
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)

    # M√©triques
    mse = mean_squared_error(y_test, y_pred)
    r2 = r2_score(y_test, y_pred)

    # Affichage des m√©triques
    col1, col2 = st.columns(2)
    with col1:
        st.metric("MSE", f"{mse:.3f}")
    with col2:
        st.metric("R¬≤", f"{r2:.3f}")

    # Visualisation Pr√©dictions vs R√©elles
    fig = go.Figure()
    fig.add_trace(go.Scatter(x=y_test, y=y_pred, mode='markers', name='Pr√©dictions'))
    fig.add_trace(go.Scatter(x=[y_test.min(), y_test.max()], y=[y_test.min(), y_test.max()], mode='lines', name='Ligne id√©ale'))
    fig.update_layout(title='Pr√©dictions vs R√©elles', xaxis_title='Valeurs R√©elles', yaxis_title='Valeurs Pr√©dites', height=500)
    st.plotly_chart(fig, use_container_width=True, key="predictions_vs_reelles")

    # Importance des features
    try:
        feature_importance = pd.DataFrame({
            'Feature': X_processed.columns.tolist(),
            'Importance': model.feature_importances_
        }).sort_values('Importance', ascending=True)

        fig_imp = px.bar(feature_importance, x='Importance', y='Feature', title='Importance des Features', orientation='h')
        st.plotly_chart(fig_imp, use_container_width=True, key="feature_importance_housing")
    except Exception as e:
        st.warning(f"Importance des features non disponible: {e}")

    st.markdown(f"""
    **üîç Analyse** :
    - Le mod√®le explique **{r2:.1%}** de la variance des prix.
    - L'erreur moyenne est de **{mse:.3f}**.
    - Colonnes cat√©gorielles trait√©es : {cat_cols if cat_cols else 'Aucune'}
    """)

# Module 9 - √Ä Propos
elif module == "üìò √Ä Propos":
    st.header("üìò √Ä Propos")

    st.markdown("""
    ## üìö **√Ä Propos de ce Cours**
    Ce cours interactif de Data Science a √©t√© d√©velopp√© pour rendre les concepts complexes accessibles et ludiques.
    - **Objectif** : Vous former aux bases de la Data Science et du Machine Learning.
    - **Public cible** : D√©butants en Data Science, analystes, ou toute personne curieuse.
    - **Technologies utilis√©es** : Python, Pandas, NumPy, Matplotlib, Seaborn, Plotly, Scikit-Learn, Streamlit.

    **Contact** :
    - **Email** : ibugueye@ngorweb.com
    - **GitHub** : ["https://github.com/ibugueye"]("https://github.com/ibugueye")

    **Licence** : MIT
    """)

# Footer
st.markdown("---")
st.markdown("""
<div style='text-align: center; color: gray;'>
üìö **Cours Interactif de Data Science** ‚Äî D√©velopp√© avec ‚ù§Ô∏è et Streamlit<br>
üîó <a href="https://github.com/ibugueye" target="_blank">GitHub</a> |
üìß <a href="mailto:ibugueye@ngorweb.com">Contact</a>
</div>
""", unsafe_allow_html=True) 
